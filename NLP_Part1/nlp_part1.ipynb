{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>m.kp.md</td>\n",
       "      <td>Экс-министр экономики Молдовы - главе МИДЭИ, цель которого сделать из республики не просителя, а донора: Надо избегать долгого нахождения н�</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>www.kp.by</td>\n",
       "      <td>Эта песня стала известна многим телезрителям благодаря сериалу Диверсант-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fanserials.tv</td>\n",
       "      <td>Банши 4 сезон 2 серия Бремя красоты смотреть онлайн!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>colorbox.spb.ru</td>\n",
       "      <td>Не Беси Меня Картинки</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tula-sport.ru</td>\n",
       "      <td>В Новомосковске сыграют следж-хоккеисты алексинской «Звезды» и сборной Китая | Т...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID              url  \\\n",
       "0   0          m.kp.md   \n",
       "1   1        www.kp.by   \n",
       "2   2    fanserials.tv   \n",
       "3   3  colorbox.spb.ru   \n",
       "4   4    tula-sport.ru   \n",
       "\n",
       "                                                                                                                                          title  \\\n",
       "0  Экс-министр экономики Молдовы - главе МИДЭИ, цель которого сделать из республики не просителя, а донора: Надо избегать долгого нахождения н�   \n",
       "1                                                                    Эта песня стала известна многим телезрителям благодаря сериалу Диверсант-2   \n",
       "2                                                                                          Банши 4 сезон 2 серия Бремя красоты смотреть онлайн!   \n",
       "3                                                                                                                         Не Беси Меня Картинки   \n",
       "4                                                           В Новомосковске сыграют следж-хоккеисты алексинской «Звезды» и сборной Китая | Т...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "train_df = train_df.dropna()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135309</td>\n",
       "      <td>www.kommersant.ru</td>\n",
       "      <td>Шестой кассационный суд в Самаре начнет работу в разных зданиях – Фото – Коммерсантъ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135310</td>\n",
       "      <td>urexpert.online</td>\n",
       "      <td>Что такое индексация алиментов, кем и в каких случаях производится, каковы порядок и правила процедуры?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135311</td>\n",
       "      <td>imperimeha.ru</td>\n",
       "      <td>Женщинам | Империя Меха - Part 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135312</td>\n",
       "      <td>national-porn.com</td>\n",
       "      <td>Небритые, волосатые киски: Порно всех стран и национальностей онлайн</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135313</td>\n",
       "      <td>2gis.ru</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                url  \\\n",
       "0  135309  www.kommersant.ru   \n",
       "1  135310    urexpert.online   \n",
       "2  135311      imperimeha.ru   \n",
       "3  135312  national-porn.com   \n",
       "4  135313            2gis.ru   \n",
       "\n",
       "                                                                                                     title  \n",
       "0                     Шестой кассационный суд в Самаре начнет работу в разных зданиях – Фото – Коммерсантъ  \n",
       "1  Что такое индексация алиментов, кем и в каких случаях производится, каковы порядок и правила процедуры?  \n",
       "2                                                                        Женщинам | Империя Меха - Part 12  \n",
       "3                                     Небритые, волосатые киски: Порно всех стран и национальностей онлайн  \n",
       "4                                                                                                       67  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df = test_df.fillna('')  \n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      " label\n",
      "0    118593\n",
      "1     16715\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = train_df['label'].value_counts()\n",
    "print(\"Class counts:\\n\", class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words = ['porn', 'порн', 'sex', 'секс', 'xxx', 'fap', 'fuck', 'milf', 'dick', 'gay', 'boob']\n",
    "\n",
    "ignore_words = ['transex', 'трансекс']\n",
    "\n",
    "smth_before_porn = r'.*[а-яА-Я]порн.*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_url(url):\n",
    "\n",
    "    # Разбиваем URL на токены по разделителю '.'\n",
    "    tokens = url.split('.')\n",
    "    \n",
    "    # Удаляем первый токен, если это 'www'\n",
    "    if tokens[0] == 'www':\n",
    "        tokens = tokens[1:]\n",
    "    \n",
    "    # Проверяем, является ли какой-либо токен IP-адресом\n",
    "    ip_pattern = r'^\\d+\\.\\d+\\.\\d+\\.\\d+'\n",
    "    for token in tokens:\n",
    "        if re.match(ip_pattern, token):\n",
    "            return \"\"  # Удаляем весь URL, если есть IP-адрес\n",
    "    \n",
    "    # Удаляем URL, если есть токен 'xn--'\n",
    "    if 'xn--' in tokens:\n",
    "        return \"\"\n",
    "    \n",
    "    # Удаляем последний токен, если он не равен 'porn'\n",
    "    if tokens[-1] != 'porn':\n",
    "        tokens = tokens[:-1]\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        if ignore_words[0] not in token and ignore_words[1] not in token and not re.match(smth_before_porn, token):\n",
    "            for bw in bad_words:\n",
    "                if bw in token:\n",
    "                    tokens[i] = bw\n",
    "               \n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        # Удаляем специальные символы\n",
    "        cleaned_token = re.sub(r'[^a-zA-Z]', '', token)\n",
    "        if cleaned_token:\n",
    "            cleaned_tokens.append(cleaned_token)\n",
    "            \n",
    "    processed_url = ' '.join(cleaned_tokens)\n",
    "    \n",
    "    return processed_url\n",
    "\n",
    "train_df['url'] = train_df['url'].apply(preprocess_url)\n",
    "test_df['url'] = test_df['url'].apply(preprocess_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "en_stemmer = PorterStemmer()\n",
    "\n",
    "# Стемминг\n",
    "def morph_process_url(text):\n",
    "    stemmed_words = []\n",
    "    words = word_tokenize(text)\n",
    "    for word in words:\n",
    "        stemmed_word = en_stemmer.stem(word)\n",
    "        stemmed_words.append(stemmed_word)\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "train_df['url'] = train_df['url'].apply(morph_process_url) \n",
    "test_df['url'] = test_df['url'].apply(morph_process_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/roman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words_eng = set(stopwords.words('english'))\n",
    "stop_words_rus = set(stopwords.words('russian'))\n",
    "\n",
    "def check_string(s):\n",
    "    russian_regex = r'^[а-яА-Я]+$'\n",
    "    latin_regex = r'^[a-zA-Z]+$'\n",
    "    \n",
    "    if re.match(russian_regex, s):\n",
    "        return True\n",
    "    elif re.match(latin_regex, s):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Преобразование текста в нижний регистр\n",
    "    text = text.lower()\n",
    "\n",
    "    # Удаление лишних пробелов\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    # Замена знаков препинания на пробелы\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n",
    "\n",
    "    # Удаление спецсимволов\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "\n",
    "    # Замена всех \"ё\" на \"е\"\n",
    "    text = text.replace('ё', 'е')\n",
    "\n",
    "    for token in text.split():\n",
    "        if ignore_words[0] not in token and ignore_words[1] not in token and not re.match(smth_before_porn, token):\n",
    "            for bw in bad_words:\n",
    "                if bw in token:\n",
    "                    text = text.replace(token, bw)\n",
    "\n",
    "    # Удаление цифр и коротких/длинных слов\n",
    "    text = ' '.join(word for word in text.split() if 3 <= len(word) <= 15 and not any(char.isdigit() for char in word))\n",
    "    \n",
    "    # Удаление стоп-слов на русском и английском языках\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words_eng and word not in stop_words_rus)\n",
    "    \n",
    "    # Замена на пустые строки, если строка не соответствует ни русскому, ни английскому языку\n",
    "    text = ' '.join('' if not check_string(word) else word for word in text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "train_df['title'] = train_df['title'].apply(preprocess_text)  \n",
    "test_df['title'] = test_df['title'].apply(preprocess_text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "import pymorphy3\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "en_stemmer = PorterStemmer()\n",
    "ru_stemmer = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "# Стемминг и лемматизация\n",
    "def morph_process(text):\n",
    "    stemmed_words = []\n",
    "    words = word_tokenize(text)\n",
    "    for word in words:\n",
    "        if word.isascii():\n",
    "            stemmed_word = en_stemmer.stem(word)\n",
    "        else:\n",
    "            stemmed_word = ru_stemmer.parse(word)[0].normal_form\n",
    "        stemmed_words.append(stemmed_word)\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "train_df['title'] = train_df['title'].apply(morph_process)  \n",
    "test_df['title'] = test_df['title'].apply(morph_process)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['combined_text'] = train_df['url'] + ' ' + train_df['title']\n",
    "test_df['combined_text'] = test_df['url'] + ' ' + test_df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>m kp</td>\n",
       "      <td>экс министр экономика молдова глава мидэя цель который сделать республика проситель донор избегать долгий нахождение</td>\n",
       "      <td>0</td>\n",
       "      <td>m kp экс министр экономика молдова глава мидэя цель который сделать республика проситель донор избегать долгий нахождение</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>kp</td>\n",
       "      <td>этот песня стать известный многий телезритель благодаря сериал диверсант</td>\n",
       "      <td>0</td>\n",
       "      <td>kp этот песня стать известный многий телезритель благодаря сериал диверсант</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fanseri</td>\n",
       "      <td>банша сезон серия бремя красота смотреть онлайн</td>\n",
       "      <td>0</td>\n",
       "      <td>fanseri банша сезон серия бремя красота смотреть онлайн</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>colorbox spb</td>\n",
       "      <td>бесить картинка</td>\n",
       "      <td>0</td>\n",
       "      <td>colorbox spb бесить картинка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tulasport</td>\n",
       "      <td>новомосковск сыграть следж хоккеист алексинский звезда сборная китай</td>\n",
       "      <td>0</td>\n",
       "      <td>tulasport новомосковск сыграть следж хоккеист алексинский звезда сборная китай</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID           url  \\\n",
       "0   0          m kp   \n",
       "1   1            kp   \n",
       "2   2       fanseri   \n",
       "3   3  colorbox spb   \n",
       "4   4     tulasport   \n",
       "\n",
       "                                                                                                                  title  \\\n",
       "0  экс министр экономика молдова глава мидэя цель который сделать республика проситель донор избегать долгий нахождение   \n",
       "1                                              этот песня стать известный многий телезритель благодаря сериал диверсант   \n",
       "2                                                                       банша сезон серия бремя красота смотреть онлайн   \n",
       "3                                                                                                       бесить картинка   \n",
       "4                                                  новомосковск сыграть следж хоккеист алексинский звезда сборная китай   \n",
       "\n",
       "   label  \\\n",
       "0      0   \n",
       "1      0   \n",
       "2      0   \n",
       "3      0   \n",
       "4      0   \n",
       "\n",
       "                                                                                                               combined_text  \n",
       "0  m kp экс министр экономика молдова глава мидэя цель который сделать республика проситель донор избегать долгий нахождение  \n",
       "1                                                kp этот песня стать известный многий телезритель благодаря сериал диверсант  \n",
       "2                                                                    fanseri банша сезон серия бремя красота смотреть онлайн  \n",
       "3                                                                                               colorbox spb бесить картинка  \n",
       "4                                             tulasport новомосковск сыграть следж хоккеист алексинский звезда сборная китай  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135309</td>\n",
       "      <td>kommers</td>\n",
       "      <td>шестой кассационный суд самара начать работа разный здание фото коммерсантъ</td>\n",
       "      <td>kommers шестой кассационный суд самара начать работа разный здание фото коммерсантъ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135310</td>\n",
       "      <td>urexpert</td>\n",
       "      <td>такой индексация алименты кто какой случай производиться каковой порядок правило процедура</td>\n",
       "      <td>urexpert такой индексация алименты кто какой случай производиться каковой порядок правило процедура</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135311</td>\n",
       "      <td>imperimeha</td>\n",
       "      <td>женщина империя мех part</td>\n",
       "      <td>imperimeha женщина империя мех part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135312</td>\n",
       "      <td>porn</td>\n",
       "      <td>небритый волосатый киска порн страна национальность онлайн</td>\n",
       "      <td>porn небритый волосатый киска порн страна национальность онлайн</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135313</td>\n",
       "      <td>gi</td>\n",
       "      <td></td>\n",
       "      <td>gi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID         url  \\\n",
       "0  135309     kommers   \n",
       "1  135310    urexpert   \n",
       "2  135311  imperimeha   \n",
       "3  135312        porn   \n",
       "4  135313          gi   \n",
       "\n",
       "                                                                                        title  \\\n",
       "0                 шестой кассационный суд самара начать работа разный здание фото коммерсантъ   \n",
       "1  такой индексация алименты кто какой случай производиться каковой порядок правило процедура   \n",
       "2                                                                    женщина империя мех part   \n",
       "3                                  небритый волосатый киска порн страна национальность онлайн   \n",
       "4                                                                                               \n",
       "\n",
       "                                                                                         combined_text  \n",
       "0                  kommers шестой кассационный суд самара начать работа разный здание фото коммерсантъ  \n",
       "1  urexpert такой индексация алименты кто какой случай производиться каковой порядок правило процедура  \n",
       "2                                                                  imperimeha женщина империя мех part  \n",
       "3                                      porn небритый волосатый киска порн страна национальность онлайн  \n",
       "4                                                                                                  gi   "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие параметры:\n",
      "{'tfidf__ngram_range': (1, 2), 'tfidf__max_df': 0.5, 'clf__C': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     23662\n",
      "           1       0.98      0.98      0.98      3400\n",
      "\n",
      "    accuracy                           1.00     27062\n",
      "   macro avg       0.99      0.99      0.99     27062\n",
      "weighted avg       1.00      1.00      1.00     27062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = train_df['combined_text']\n",
    "y = train_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.5, 0.75, 1.0),\n",
    "    'tfidf__ngram_range': [(1, 2), (1, 3)],\n",
    "    'clf__C': (1, 100),\n",
    "}\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipeline, parameters, cv=5, scoring='f1', n_jobs=-1, n_iter=6)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Наилучшие параметры:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99675   0.99776   0.99725     23662\n",
      "           1    0.98430   0.97735   0.98081      3400\n",
      "\n",
      "    accuracy                        0.99520     27062\n",
      "   macro avg    0.99053   0.98756   0.98903     27062\n",
      "weighted avg    0.99519   0.99520   0.99519     27062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Используем выбранные параметры\n",
    "tfidf_params = {\n",
    "    'max_df': 0.5,\n",
    "    'ngram_range': (1, 2)\n",
    "}\n",
    "\n",
    "clf_params = {\n",
    "    'C': 100\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
    "    ('clf', LogisticRegression(solver='liblinear', **clf_params))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование тестовых предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real_test = test_df['combined_text']\n",
    "y_real_pred = pipeline.predict(X_real_test)\n",
    "\n",
    "predictions_df = pd.DataFrame({'ID': test_df['ID'], 'label': y_real_pred})\n",
    "\n",
    "predictions_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
